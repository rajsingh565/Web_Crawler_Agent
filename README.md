
# ğŸ•·ï¸ Web Crawler Agent

## ğŸš€ Project Overview
This project is part of the **Agentic AI Challenge**. It demonstrates an intelligent web crawler agent built using **LangChain** or **CrewAI**. The agent accepts a URL input via a **Streamlit UI**, crawls the webpage, and extracts meaningful content such as:

- ğŸ“ Title
- ğŸ”  Headings (H1-H3)
- ğŸ“„ Paragraphs
- ğŸ”— Links
- ğŸ–¼ï¸ Images

## ğŸ› ï¸ Technologies Used
- LangChain / CrewAI
- Streamlit
- BeautifulSoup / Playwright / Selenium
- Python 3

## Screenshot
![image alt](https://github.com/rajsingh565/Web_Crawler_Agent/blob/c7c890b3073b9d531b2c53c734dc407efa222fd3/Screenshot1.png)
![image_alt](https://github.com/rajsingh565/Web_Crawler_Agent/blob/1e04b3a0ff97286391ffd17b0bad44e7d0f1cae6/Screenshot2.png)
## ğŸ’¡ Features
- Simple and intuitive Streamlit interface
- Real-time crawling and content extraction
- Structured display of extracted data
- Tabs for Overview, Headings, Paragraphs, Links, Images, and Raw JSON

## ğŸ§‘â€ğŸ’» How to Run
1. Clone the repository:
```bash
git clone https://github.com/rajsingh565/Web_Crawler_Agent.git
cd Web_Crawler_Agent
```
2. Install dependencies:
```bash
pip install -r requirements.txt
```
3. Run the Streamlit app:
```bash
streamlit run app.py
```

## ğŸŒ Usage
Enter a website URL in the input field and click **Crawl Website**. The agent will fetch the page and display structured content in various tabs.

## ğŸ“¬ Contact & Credits
Developed by **Raj Singh** 

Feel free to contribute or raise issues!
